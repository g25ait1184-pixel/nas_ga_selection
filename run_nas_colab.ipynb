{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3s-M_ri859Dt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "bae7295e-6703-4b98-e0ae-ae71e969c32e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-255f180f-548b-407c-b627-e03c7433e6a0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-255f180f-548b-407c-b627-e03c7433e6a0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import io\n",
        "import os\n",
        "\n",
        "# Step 1: Ask user to upload a ZIP file\n",
        "print(\"Please upload your ZIP file:\")\n",
        "uploaded = files.upload()  # Opens file picker dialog\n",
        "\n",
        "# Step 2: Extract the uploaded ZIP file\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.zip'):\n",
        "        print(f\"Unzipping {filename}...\")\n",
        "        with zipfile.ZipFile(io.BytesIO(uploaded[filename]), 'r') as zip_ref:\n",
        "            zip_ref.extractall('/content/')\n",
        "        print(\"Extraction complete!\")\n",
        "        print(\"Files extracted to /content/\")\n",
        "\n",
        "# Step 3: List extracted files\n",
        "print(\"\\nExtracted folder structure:\")\n",
        "!ls -R /content/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Run both: Tournament vs Roulette (Colab cell)\n",
        "# ---------------------------\n",
        "import os, shutil, zipfile, pickle, time\n",
        "from pathlib import Path\n",
        "PROJECT_DIR = None\n",
        "# === Logging helper ===\n",
        "def enable_logging(run_id):\n",
        "    run_dir = os.path.join(run_base, f'run_{run_id}')\n",
        "    os.makedirs(run_dir, exist_ok=True)\n",
        "    log_path = os.path.join(run_dir, \"nas_run.log\")\n",
        "\n",
        "    log_file = open(log_path, \"w\")\n",
        "\n",
        "    class Tee(object):\n",
        "        def __init__(self, *files):\n",
        "            self.files = files\n",
        "        def write(self, data):\n",
        "            for f in self.files:\n",
        "                f.write(data)\n",
        "        def flush(self):\n",
        "            for f in self.files:\n",
        "                try: f.flush()\n",
        "                except: pass\n",
        "\n",
        "    new_stdout = Tee(sys.stdout, log_file)\n",
        "    new_stderr = Tee(sys.stderr, log_file)\n",
        "\n",
        "    print(f\"\\n=== Logging enabled for run {run_id} ===\")\n",
        "    print(f\"Output saved to: {log_path}\\n\")\n",
        "\n",
        "    return log_file, new_stdout, new_stderr\n",
        "\n",
        "\n",
        "# 0) Unzip if project folder not present\n",
        "if not any(p for p in os.listdir(CONTENT) if 'nas' in p.lower() and os.path.isdir(os.path.join(CONTENT, p))):\n",
        "    print(\"Project folder not found in /content. Unzipping uploaded ZIP...\")\n",
        "    if not os.path.exists(ZIP_PATH):\n",
        "        raise FileNotFoundError(f\"ZIP file not found at {ZIP_PATH}. Upload first or update ZIP_PATH.\")\n",
        "    shutil.copy(ZIP_PATH, CONTENT)\n",
        "    zip_target = os.path.join(CONTENT, os.path.basename(ZIP_PATH))\n",
        "    with zipfile.ZipFile(zip_target, 'r') as zf:\n",
        "        zf.extractall(CONTENT)\n",
        "    print(\"Unzipped to /content/\")\n",
        "else:\n",
        "    print(\"Project folder found in /content/ - skipping unzip.\")\n",
        "\n",
        "# 1) Detect project folder (prefer one with 'nas' in name)\n",
        "candidates = [p for p in os.listdir(CONTENT) if os.path.isdir(os.path.join(CONTENT, p))]\n",
        "for c in candidates:\n",
        "    if 'nas' in c.lower():\n",
        "        PROJECT_DIR = os.path.join(CONTENT, c)\n",
        "        break\n",
        "if PROJECT_DIR is None:\n",
        "    # fallback to most recently modified dir in /content\n",
        "    dirs = [(os.path.join(CONTENT, d), os.path.getmtime(os.path.join(CONTENT, d))) for d in candidates]\n",
        "    dirs.sort(key=lambda x: x[1], reverse=True)\n",
        "    PROJECT_DIR = dirs[0][0] if dirs else CONTENT\n",
        "\n",
        "print(\"Using project dir:\", PROJECT_DIR)\n",
        "\n",
        "# 2) Add project dir to sys.path and cd into it\n",
        "import sys\n",
        "if PROJECT_DIR not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_DIR)\n",
        "os.chdir(PROJECT_DIR)\n",
        "print(\"Working directory:\", os.getcwd())\n",
        "\n",
        "# 3) Ensure outputs base exists\n",
        "run_base = os.path.join(PROJECT_DIR, 'outputs')\n",
        "os.makedirs(run_base, exist_ok=True)\n",
        "# determine next two run ids\n",
        "existing_runs = [d for d in os.listdir(run_base) if d.startswith('run_') and os.path.isdir(os.path.join(run_base, d))]\n",
        "next_run = len(existing_runs) + 1\n",
        "run_tournament = next_run\n",
        "run_roulette = next_run + 1\n",
        "\n",
        "# 4) Import project modules (model_ga, model_cnn). If import fails, raise informative error.\n",
        "try:\n",
        "    from model_ga import GeneticAlgorithm\n",
        "    from model_cnn import CNN\n",
        "except Exception as e:\n",
        "    raise ImportError(f\"Failed to import project modules (model_ga/model_cnn). Error: {e}\")\n",
        "\n",
        "# 5) Prepare dataset loaders (small subsets for quick runs)\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])\n",
        "data_root = os.path.join(PROJECT_DIR, 'data')\n",
        "os.makedirs(data_root, exist_ok=True)\n",
        "\n",
        "trainset = CIFAR10(root=data_root, train=True, download=True, transform=transform)\n",
        "valset = CIFAR10(root=data_root, train=False, download=True, transform=transform)\n",
        "# small subsets to keep runtime short (adjust if you want longer runs)\n",
        "train_subset = Subset(trainset, range(min(5000, len(trainset))))\n",
        "val_subset   = Subset(valset,   range(min(1000, len(valset))))\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=256, shuffle=True)\n",
        "val_loader   = DataLoader(val_subset, batch_size=256, shuffle=False)\n",
        "\n",
        "# helper logging\n",
        "def log(msg):\n",
        "    print(msg, flush=True)\n",
        "\n",
        "# 6) Function to run an experiment (selection_method: 'tournament' or 'roulette')\n",
        "def run_experiment(selection_method, population_size=5, generations=2, run_id=1):\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"STARTING RUN {run_id} (selection={selection_method})\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    ga = GeneticAlgorithm(\n",
        "        population_size=population_size,\n",
        "        generations=generations,\n",
        "        mutation_rate=0.3,\n",
        "        crossover_rate=0.7\n",
        "    )\n",
        "\n",
        "    t0 = time.time()\n",
        "    best_arch = ga.evolve(train_loader, val_loader, device, run=run_id, selection_method=selection_method)\n",
        "    elapsed = time.time() - t0\n",
        "\n",
        "    run_dir = os.path.join(run_base, f'run_{run_id}')\n",
        "    os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "    with open(os.path.join(run_dir, \"best_arch.pkl\"), 'wb') as f:\n",
        "        pickle.dump(best_arch, f)\n",
        "\n",
        "    print(f\"Completed run_{run_id} in {elapsed:.1f} s. Best arch saved to {run_dir}/best_arch.pkl\")\n",
        "\n",
        "    summary = {\n",
        "        'run_id': run_id,\n",
        "        'selection': selection_method,\n",
        "        'genes': best_arch.genes,\n",
        "        'accuracy': best_arch.accuracy,\n",
        "        'fitness_original': best_arch.fitness_original,\n",
        "        'fitness_weighted': best_arch.fitness_weighted,\n",
        "        'param_count': sum(p.numel() for p in CNN(best_arch.genes).parameters()),\n",
        "        'run_dir': run_dir\n",
        "    }\n",
        "    return summary\n",
        "\n",
        "# ---- RUN 1: TOURNAMENT ----\n",
        "log_file1, new_out1, new_err1 = enable_logging(run_tournament)\n",
        "orig_stdout, orig_stderr = sys.stdout, sys.stderr\n",
        "\n",
        "sys.stdout, sys.stderr = new_out1, new_err1\n",
        "summary_tourn = run_experiment(\"tournament\", population_size=2, generations=2, run_id=run_tournament)\n",
        "sys.stdout.flush(); sys.stderr.flush()\n",
        "sys.stdout, sys.stderr = orig_stdout, orig_stderr\n",
        "log_file1.close()\n",
        "\n",
        "\n",
        "# ---- RUN 2: ROULETTE ----\n",
        "log_file2, new_out2, new_err2 = enable_logging(run_roulette)\n",
        "orig_stdout, orig_stderr = sys.stdout, sys.stderr\n",
        "\n",
        "sys.stdout, sys.stderr = new_out2, new_err2\n",
        "summary_roul = run_experiment(\"roulette\", population_size=2, generations=2, run_id=run_roulette)\n",
        "sys.stdout.flush(); sys.stderr.flush()\n",
        "sys.stdout, sys.stderr = orig_stdout, orig_stderr\n",
        "log_file2.close()\n",
        "\n",
        "\n",
        "# ==========================\n",
        "# 8) Final Comparison\n",
        "# ==========================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARISON SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"Run {summary_tourn['run_id']} (Tournament):\")\n",
        "print(f\"  Accuracy: {summary_tourn['accuracy']}\")\n",
        "print(f\"  Fitness (orig): {summary_tourn['fitness_original']}\")\n",
        "print(f\"  Fitness (weighted): {summary_tourn['fitness_weighted']}\")\n",
        "print(f\"  Params: {summary_tourn['param_count']}\")\n",
        "print(f\"  Saved at: {summary_tourn['run_dir']}\\n\")\n",
        "\n",
        "print(f\"Run {summary_roul['run_id']} (Roulette):\")\n",
        "print(f\"  Accuracy: {summary_roul['accuracy']}\")\n",
        "print(f\"  Fitness (orig): {summary_roul['fitness_original']}\")\n",
        "print(f\"  Fitness (weighted): {summary_roul['fitness_weighted']}\")\n",
        "print(f\"  Params: {summary_roul['param_count']}\")\n",
        "print(f\"  Saved at: {summary_roul['run_dir']}\\n\")\n",
        "\n",
        "winner = summary_tourn if summary_tourn['fitness_original'] >= summary_roul['fitness_original'] else summary_roul\n",
        "\n",
        "print(\"WINNER (by original fitness):\")\n",
        "print(f\"  Run {winner['run_id']} - selection: {winner['selection']}\")\n",
        "print(f\"  Accuracy: {winner['accuracy']}, Fitness (orig): {winner['fitness_original']}, Params: {winner['param_count']}\")\n",
        "print(\"\\nAll done. Two runs completed and saved to outputs directory.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "3Xd_Yxra_o3D",
        "outputId": "2f01ca12-25c9-47fe-a898-dc086561ab07"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'CONTENT' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2065250388.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlog_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# 0) Unzip if project folder not present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'nas'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Project folder not found in /content. Unzipping uploaded ZIP...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZIP_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CONTENT' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Run both: Tournament vs Roulette\n",
        "# ---------------------------\n",
        "import os, shutil, zipfile, pickle, time\n",
        "from pathlib import Path\n",
        "\n",
        "ZIP_PATH = \"/mnt/data/nas-ga-basic-main.zip\"   # your uploaded zip (from conversation history)\n",
        "CONTENT = \"/content\"\n",
        "PROJECT_DIR = None\n",
        "def enable_logging(run_id):\n",
        "    run_dir = os.path.join(run_base, f'run_{run_id}')\n",
        "    os.makedirs(run_dir, exist_ok=True)\n",
        "    log_path = os.path.join(run_dir, \"nas_run.log\")\n",
        "\n",
        "    log_f = open(log_path, \"w\")\n",
        "\n",
        "    class Tee(object):\n",
        "        def __init__(self, *files):\n",
        "            self.files = files\n",
        "        def write(self, data):\n",
        "            for f in self.files:\n",
        "                f.write(data)\n",
        "        def flush(self):\n",
        "            for f in self.files:\n",
        "                try: f.flush()\n",
        "                except: pass\n",
        "\n",
        "    # Redirect ALL stdout + stderr to BOTH console AND log file\n",
        "    sys.stdout = Tee(sys.stdout, log_f)\n",
        "    sys.stderr = Tee(sys.stderr, log_f)\n",
        "\n",
        "    print(f\"\\n=== Logging enabled for run {run_id} ===\")\n",
        "    print(f\"Output saved to: {log_path}\\n\")\n",
        "\n",
        "    return log_f\n",
        "# 0) Unzip if project folder not present\n",
        "if not any(p for p in os.listdir(CONTENT) if 'nas' in p.lower() and os.path.isdir(os.path.join(CONTENT, p))):\n",
        "    print(\"Project folder not found in /content. Unzipping uploaded ZIP...\")\n",
        "    if not os.path.exists(ZIP_PATH):\n",
        "        raise FileNotFoundError(f\"ZIP file not found at {ZIP_PATH}. Upload first or update ZIP_PATH.\")\n",
        "    shutil.copy(ZIP_PATH, CONTENT)\n",
        "    zip_target = os.path.join(CONTENT, os.path.basename(ZIP_PATH))\n",
        "    with zipfile.ZipFile(zip_target, 'r') as zf:\n",
        "        zf.extractall(CONTENT)\n",
        "    print(\"Unzipped to /content/\")\n",
        "else:\n",
        "    print(\"Project folder found in /content/ - skipping unzip.\")\n",
        "\n",
        "# 1) Detect project folder (prefer one with 'nas' in name)\n",
        "candidates = [p for p in os.listdir(CONTENT) if os.path.isdir(os.path.join(CONTENT, p))]\n",
        "for c in candidates:\n",
        "    if 'nas' in c.lower():\n",
        "        PROJECT_DIR = os.path.join(CONTENT, c)\n",
        "        break\n",
        "if PROJECT_DIR is None:\n",
        "    # fallback to most recently modified dir in /content\n",
        "    dirs = [(os.path.join(CONTENT, d), os.path.getmtime(os.path.join(CONTENT, d))) for d in candidates]\n",
        "    dirs.sort(key=lambda x: x[1], reverse=True)\n",
        "    PROJECT_DIR = dirs[0][0] if dirs else CONTENT\n",
        "\n",
        "print(\"Using project dir:\", PROJECT_DIR)\n",
        "\n",
        "# 2) Add project dir to sys.path and cd into it\n",
        "import sys\n",
        "if PROJECT_DIR not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_DIR)\n",
        "os.chdir(PROJECT_DIR)\n",
        "print(\"Working directory:\", os.getcwd())\n",
        "\n",
        "# 3) Ensure outputs base exists\n",
        "run_base = os.path.join(PROJECT_DIR, 'outputs')\n",
        "os.makedirs(run_base, exist_ok=True)\n",
        "# determine next two run ids\n",
        "existing_runs = [d for d in os.listdir(run_base) if d.startswith('run_') and os.path.isdir(os.path.join(run_base, d))]\n",
        "next_run = len(existing_runs) + 1\n",
        "run_tournament = next_run\n",
        "run_roulette = next_run + 1\n",
        "\n",
        "# 4) Import project modules (model_ga, model_cnn). If import fails, raise informative error.\n",
        "try:\n",
        "    from model_ga import GeneticAlgorithm\n",
        "    from model_cnn import CNN\n",
        "except Exception as e:\n",
        "    raise ImportError(f\"Failed to import project modules (model_ga/model_cnn). Error: {e}\")\n",
        "\n",
        "# 5) Prepare dataset loaders (small subsets for quick runs)\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])\n",
        "data_root = os.path.join(PROJECT_DIR, 'data')\n",
        "os.makedirs(data_root, exist_ok=True)\n",
        "\n",
        "trainset = CIFAR10(root=data_root, train=True, download=True, transform=transform)\n",
        "valset = CIFAR10(root=data_root, train=False, download=True, transform=transform)\n",
        "# small subsets to keep runtime short (adjust if you want longer runs)\n",
        "train_subset = Subset(trainset, range(min(5000, len(trainset))))\n",
        "val_subset   = Subset(valset,   range(min(1000, len(valset))))\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=256, shuffle=True)\n",
        "val_loader   = DataLoader(val_subset, batch_size=256, shuffle=False)\n",
        "\n",
        "# helper logging\n",
        "def log(msg):\n",
        "    print(msg, flush=True)\n",
        "\n",
        "# 6) Function to run an experiment (selection_method: 'tournament' or 'roulette')\n",
        "def run_experiment(selection_method, population_size=5, generations=2, run_id=1):\n",
        "    log(\"\\n\" + \"=\"*60)\n",
        "    log(f\"STARTING RUN {run_id}  (selection={selection_method})\")\n",
        "    log(\"=\"*60)\n",
        "    ga = GeneticAlgorithm(\n",
        "        population_size=population_size,\n",
        "        generations=generations,\n",
        "        mutation_rate=0.3,\n",
        "        crossover_rate=0.7\n",
        "    )\n",
        "    t0 = time.time()\n",
        "    best_arch = ga.evolve(train_loader, val_loader, device, run=run_id, selection_method=selection_method)\n",
        "    elapsed = time.time() - t0\n",
        "    # create run dir (evolve may have created it; ensure exists)\n",
        "    run_dir = os.path.join(run_base, f'run_{run_id}')\n",
        "    os.makedirs(run_dir, exist_ok=True)\n",
        "    # save best arch\n",
        "    with open(os.path.join(run_dir, \"best_arch.pkl\"), 'wb') as f:\n",
        "        pickle.dump(best_arch, f)\n",
        "    log(f\"Completed run_{run_id} in {elapsed:.1f} s. Best arch saved to {run_dir}/best_arch.pkl\")\n",
        "    # return summary\n",
        "    summary = {\n",
        "        'run_id': run_id,\n",
        "        'selection': selection_method,\n",
        "        'genes': getattr(best_arch, 'genes', None),\n",
        "        'accuracy': getattr(best_arch, 'accuracy', None),\n",
        "        'fitness_original': getattr(best_arch, 'fitness_original', getattr(best_arch, 'fitness', None)),\n",
        "        'fitness_weighted': getattr(best_arch, 'fitness_weighted', None),\n",
        "        'param_count': sum(p.numel() for p in CNN(getattr(best_arch,'genes',{})).parameters()) if getattr(best_arch,'genes',None) else None,\n",
        "        'run_dir': run_dir\n",
        "    }\n",
        "    return summary\n",
        "\n",
        "# 7) Run both experiments back-to-back\n",
        "log_file, new_stdout, new_stderr = enable_logging(run_tournament)\n",
        "orig_stdout, orig_stderr = sys.stdout, sys.stderr\n",
        "sys.stdout, sys.stderr = new_stdout, new_stderr\n",
        "summary_tourn = run_experiment('tournament', population_size=2, generations=2, run_id=run_tournament)\n",
        "sys.stdout.flush(); sys.stderr.flush()\n",
        "sys.stdout, sys.stderr = orig_out, orig_err\n",
        "log_file.close()\n",
        "\n",
        "log_file2, new_out2, new_err2 = enable_logging(run_roulette)\n",
        "orig_out, orig_err = sys.stdout, sys.stderr\n",
        "sys.stdout, sys.stderr = new_out2, new_err2\n",
        "summary_roul = run_experiment('roulette', population_size=2, generations=2, run_id=run_roulette)\n",
        "sys.stdout.flush(); sys.stderr.flush()\n",
        "sys.stdout, sys.stderr = orig_out, orig_err\n",
        "log_file2.close()\n",
        "\n",
        "# 8) Compare results\n",
        "log(\"\\n\" + \"=\"*60)\n",
        "log(\"COMPARISON SUMMARY\")\n",
        "log(\"=\"*60)\n",
        "log(f\"Run {summary_tourn['run_id']} (Tournament):\")\n",
        "log(f\"  Accuracy: {summary_tourn['accuracy']}\")\n",
        "log(f\"  Fitness (orig): {summary_tourn['fitness_original']}\")\n",
        "log(f\"  Fitness (weighted): {summary_tourn['fitness_weighted']}\")\n",
        "log(f\"  Params: {summary_tourn['param_count']}\")\n",
        "log(f\"  Saved at: {summary_tourn['run_dir']}\\n\")\n",
        "\n",
        "log(f\"Run {summary_roul['run_id']} (Roulette):\")\n",
        "log(f\"  Accuracy: {summary_roul['accuracy']}\")\n",
        "log(f\"  Fitness (orig): {summary_roul['fitness_original']}\")\n",
        "log(f\"  Fitness (weighted): {summary_roul['fitness_weighted']}\")\n",
        "log(f\"  Params: {summary_roul['param_count']}\")\n",
        "log(f\"  Saved at: {summary_roul['run_dir']}\\n\")\n",
        "\n",
        "# 9) Quick winner decision (by original fitness)\n",
        "winner = summary_tourn if (summary_tourn['fitness_original'] or 0) >= (summary_roul['fitness_original'] or 0) else summary_roul\n",
        "log(\"WINNER (by original fitness):\")\n",
        "log(f\"  Run {winner['run_id']} - selection: {winner['selection']}\")\n",
        "log(f\"  Accuracy: {winner['accuracy']}, Fitness (orig): {winner['fitness_original']}, Params: {winner['param_count']}\")\n",
        "log(\"\\nAll done. Two runs completed and saved to outputs directory.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "lzKyF8m7hCjh",
        "outputId": "d4b83fd8-ca34-47f7-ef82-22bc68c6ad88"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project folder found in /content/ - skipping unzip.\n",
            "Using project dir: /content/nas-ga-basic-main\n",
            "Working directory: /content/nas-ga-basic-main\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 41.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Logging enabled for run 3 ===\n",
            "Output saved to: /content/nas-ga-basic-main/outputs/run_3/nas_run.log\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnsupportedOperation",
          "evalue": "not readable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1196431095.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;31m# 7) Run both experiments back-to-back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m \u001b[0mlog_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_stdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_stderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menable_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_tournament\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0morig_stdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_stderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_stdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_stderr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnsupportedOperation\u001b[0m: not readable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Path to your folder\n",
        "folder_path = '/content/nas-ga-basic-main'\n",
        "\n",
        "# Create ZIP file\n",
        "zip_path = '/content/nas-ga-basic-main.zip'\n",
        "shutil.make_archive('/content/nas-ga-basic-main', 'zip', folder_path)\n",
        "\n",
        "# Download to local computer\n",
        "files.download(zip_path)"
      ],
      "metadata": {
        "id": "K4NrYlQR-S0z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}